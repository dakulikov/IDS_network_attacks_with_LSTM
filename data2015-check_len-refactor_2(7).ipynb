{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import socket, struct\n",
    "from sklearn.preprocessing import OneHotEncoder, normalize, MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "#import keras_metrics as km\n",
    "from keras.layers import merge, Input, Dropout, Concatenate,Activation\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class SkMetrics(Callback):\n",
    "    def __init__(self,batchsize):\n",
    "        self.batchsize = batchsize\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.confusion = []\n",
    "        self.precision = []\n",
    "        self.recall = []\n",
    "        self.f1s = []\n",
    "        self.kappa = []        \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        score = numpy.asarray(self.model.predict(self.validation_data[0],batch_size = self.batchsize))\n",
    "        predict = numpy.round(numpy.asarray(self.model.predict(self.validation_data[0],batch_size = self.batchsize)))\n",
    "        targ = self.validation_data[1]\n",
    "        targ = targ.flatten()\n",
    "        predict = predict.flatten()\n",
    "        self.confusion.append(confusion_matrix(targ, predict, labels=[0,1]))\n",
    "        self.precision.append(precision_score(targ, predict))\n",
    "        self.recall.append(recall_score(targ, predict))\n",
    "        self.f1s.append(f1_score(targ, predict))\n",
    "        self.kappa.append(cohen_kappa_score(targ, predict))\n",
    "\n",
    "def getModel(neurons, layers, inputshape, batchsize):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape = (batchsize, inputshape[0],inputshape[1]), return_sequences=True, stateful=False))\n",
    "    for i in range(layers):\n",
    "        model.add(LSTM(neurons, return_sequences=False, stateful=False))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    model.compile(optimizer=\"adam\", \n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanet/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (1,3,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/vanet/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./UNSW-NB15_1.csv', header=None)\n",
    "data1a = numpy.asarray(data)\n",
    "data1a = numpy.delete(data1a, 47, 1)\n",
    "data2 = pd.read_csv('./UNSW-NB15_2.csv', header=None)\n",
    "data2a = numpy.asarray(data2)\n",
    "data2a = numpy.delete(data2a, 47, 1)\n",
    "data3 = pd.read_csv('./UNSW-NB15_3.csv', header=None)\n",
    "data3a = numpy.asarray(data3)\n",
    "data3a = numpy.delete(data3a, 47, 1)\n",
    "data = []\n",
    "temp = len(data1a) + len(data2a) + len(data3a)\n",
    "data.append(data1a)\n",
    "data.append(data2a)\n",
    "data.append(data3a)\n",
    "\n",
    "data = numpy.reshape(numpy.asarray(data),(temp, 48))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iptoint(ip):\n",
    "    return struct.unpack(\"!I\",(socket.inet_aton(ip)))[0] \n",
    "\n",
    "def parse(data):\n",
    "    protocols = dict()\n",
    "    protocolsNum = 1\n",
    "    services  = dict()\n",
    "    servicesNum = 1\n",
    "    states = dict()\n",
    "    statesNum = 1\n",
    "    numMalicious = 0\n",
    "    numNormal = 0\n",
    "    x = []\n",
    "    y = []\n",
    "    for dataRaw in data:\n",
    "        dataRaw[0] = iptoint(dataRaw[0])\n",
    "        dataRaw[2] = iptoint(dataRaw[2])\n",
    "        #Source IP\n",
    "        if (type(dataRaw[39]) == str):\n",
    "            if (dataRaw[39] !=  \" \"):\n",
    "                dataRaw[39] = int(dataRaw[39],0)\n",
    "            else:\n",
    "                dataRaw[39] = 0\n",
    "        if (type(dataRaw[1]) == str):\n",
    "            if (dataRaw[1] != \"-\"):\n",
    "                dataRaw[1] = int(dataRaw[1],0)\n",
    "            else:\n",
    "                dataRaw[1] = 0\n",
    "        #Dest IP\n",
    "        if (type(dataRaw[3]) == str):\n",
    "            if (dataRaw[3] != \"-\"):\n",
    "                dataRaw[3] = int(dataRaw[3],0)\n",
    "            else:\n",
    "                dataRaw[3] = 0\n",
    "        if (dataRaw[4] in protocols):\n",
    "            dataRaw[4] = protocols.get(dataRaw[4])\n",
    "        else:\n",
    "            protocols.update({dataRaw[4]:protocolsNum})\n",
    "            dataRaw[4] = protocolsNum\n",
    "            protocolsNum += 1\n",
    "\n",
    "        if (type(dataRaw[4])!= int):\n",
    "            print (dataRaw[4])\n",
    " \n",
    "        if (dataRaw[5] in states):\n",
    "            dataRaw[5] = states.get(dataRaw[5])\n",
    "        else:\n",
    "            states.update({dataRaw[5]:statesNum})\n",
    "            dataRaw[5] = statesNum\n",
    "            statesNum += 1\n",
    "        if (type(dataRaw[5])!=int):\n",
    "            print (dataRaw[5])\n",
    "        if (dataRaw[13] in services):\n",
    "            dataRaw[13] = services.get(dataRaw[13])\n",
    "        else:\n",
    "            services.update({dataRaw[13]:servicesNum})\n",
    "            dataRaw[13] = servicesNum\n",
    "            servicesNum += 1\n",
    "        if (type(dataRaw[13])!=int):\n",
    "            print (dataRaw[13])\n",
    "        if (dataRaw[47] == 1):\n",
    "            numMalicious = numMalicious + 1\n",
    "            y.append(1)\n",
    "        else:\n",
    "            numNormal = numNormal + 1\n",
    "            y.append(0)\n",
    "        i = 0\n",
    "        for data in dataRaw:\n",
    "            if (type(data) == str):\n",
    "                print(dataRaw,data,i)\n",
    "            i = i+1\n",
    "        x.append(dataRaw)\n",
    "    print(\"normal = \",numNormal)\n",
    "    print(\"Malicious = \", numMalicious)\n",
    "    print(protocols)\n",
    "    print(states)\n",
    "    print(services)\n",
    "    return [x, y]\n",
    "\n",
    "\n",
    "def optimizeParameters(data, labels, scorefunc):\n",
    "    # Выбираем k лучших признаков\n",
    "    selecter = SelectKBest(score_func=scorefunc, k=10)\n",
    "    selecter.fit(data, labels)\n",
    "    \n",
    "    # Какие именно выбрали\n",
    "    params = []\n",
    "    index = []\n",
    "    params = selecter.get_support()\n",
    "    count = 0\n",
    "    \n",
    "    for param in params :\n",
    "        if param == True :\n",
    "            index.append(count)\n",
    "        count += 1\n",
    "    \n",
    "\n",
    "    index_file = open(\"index.txt\" , \"w\")\n",
    "    for i in index : \n",
    "        index_file.write(str(i) + \" \")\n",
    "    index_file.close()\n",
    "\n",
    "    return selecter.transform(data)\n",
    "\n",
    "def drawGraphic(dataset, labels, normalCount, malwareCount):\n",
    "\n",
    "    parametersCount = len(dataset[0])\n",
    "\n",
    "    normalCountList = [0] * parametersCount\n",
    "    malwareCountList = [0] * parametersCount\n",
    "\n",
    "    for i in range(0, len(dataset)):\n",
    "        if(i < normalCount):\n",
    "            for j in range(0, parametersCount):\n",
    "                normalCountList[j] += dataset[i][j]\n",
    "        else:\n",
    "            for j in range(0, parametersCount):\n",
    "                malwareCountList[j] += dataset[i][j]\n",
    "\n",
    "    for i in range(0, parametersCount):\n",
    "        normalCountList[i] = normalCountList[i]\n",
    "        malwareCountList[i] = malwareCountList[i] \n",
    "\n",
    "    ts = pd.DataFrame({'normal': normalCountList,\n",
    "                       'malware': malwareCountList})\n",
    "    ts.plot()\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "    \n",
    "def ROC(ROC_MODEL , ROC_X, ROC_Y):\n",
    "    probs = ROC_MODEL.predict(ROC_X)\n",
    "    ROC_Y = ROC_Y.flatten()\n",
    "    probs = probs.flatten()\n",
    "    FPr, TPr, threshold = metrics.roc_curve(ROC_Y, probs)\n",
    "    roc_auc = metrics.auc(FPr, TPr)\n",
    "    lw = 2\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(FPr, TPr, lw = lw , label='Logistic Regression (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('Log_ROC')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal =  1867614\n",
      "Malicious =  232389\n",
      "{'udp': 1, 'arp': 2, 'tcp': 3, 'ospf': 4, 'icmp': 5, 'igmp': 6, 'sctp': 7, 'udt': 8, 'sep': 9, 'sun-nd': 10, 'swipe': 11, 'mobile': 12, 'pim': 13, 'rtp': 14, 'ipnip': 15, 'ip': 16, 'ggp': 17, 'st2': 18, 'egp': 19, 'cbt': 20, 'emcon': 21, 'nvp': 22, 'igp': 23, 'xnet': 24, 'argus': 25, 'bbn-rcc': 26, 'chaos': 27, 'pup': 28, 'hmp': 29, 'mux': 30, 'dcn': 31, 'prm': 32, 'trunk-1': 33, 'xns-idp': 34, 'trunk-2': 35, 'leaf-1': 36, 'leaf-2': 37, 'irtp': 38, 'rdp': 39, 'iso-tp4': 40, 'netblt': 41, 'mfe-nsp': 42, 'merit-inp': 43, '3pc': 44, 'xtp': 45, 'idpr': 46, 'tp++': 47, 'ddp': 48, 'idpr-cmtp': 49, 'ipv6': 50, 'il': 51, 'idrp': 52, 'ipv6-frag': 53, 'sdrp': 54, 'ipv6-route': 55, 'gre': 56, 'rsvp': 57, 'mhrp': 58, 'bna': 59, 'esp': 60, 'i-nlsp': 61, 'narp': 62, 'ipv6-no': 63, 'tlsp': 64, 'skip': 65, 'ipv6-opts': 66, 'any': 67, 'cftp': 68, 'sat-expak': 69, 'kryptolan': 70, 'rvd': 71, 'ippc': 72, 'sat-mon': 73, 'ipcv': 74, 'visa': 75, 'cpnx': 76, 'cphb': 77, 'wsn': 78, 'pvp': 79, 'br-sat-mon': 80, 'wb-mon': 81, 'wb-expak': 82, 'iso-ip': 83, 'secure-vmtp': 84, 'vmtp': 85, 'vines': 86, 'ttp': 87, 'nsfnet-igp': 88, 'dgp': 89, 'tcf': 90, 'eigrp': 91, 'sprite-rpc': 92, 'larp': 93, 'mtp': 94, 'ax.25': 95, 'ipip': 96, 'micp': 97, 'aes-sp3-d': 98, 'encap': 99, 'etherip': 100, 'pri-enc': 101, 'gmtp': 102, 'pnni': 103, 'ifmp': 104, 'aris': 105, 'qnx': 106, 'a/n': 107, 'scps': 108, 'snp': 109, 'ipcomp': 110, 'compaq-peer': 111, 'ipx-n-ip': 112, 'vrrp': 113, 'zero': 114, 'pgm': 115, 'iatp': 116, 'ddx': 117, 'l2tp': 118, 'srp': 119, 'stp': 120, 'smp': 121, 'uti': 122, 'sm': 123, 'ptp': 124, 'fire': 125, 'crtp': 126, 'isis': 127, 'crudp': 128, 'sccopmce': 129, 'sps': 130, 'pipe': 131, 'iplt': 132, 'unas': 133, 'fc': 134, 'ib': 135}\n",
      "{'CON': 1, 'INT': 2, 'FIN': 3, 'URH': 4, 'REQ': 5, 'ECO': 6, 'RST': 7, 'CLO': 8, 'TXD': 9, 'URN': 10, 'no': 11, 'ACC': 12, 'PAR': 13, 'MAS': 14, 'TST': 15, 'ECR': 16}\n",
      "{'dns': 1, '-': 2, 'http': 3, 'smtp': 4, 'ftp-data': 5, 'ftp': 6, 'ssh': 7, 'pop3': 8, 'snmp': 9, 'ssl': 10, 'irc': 11, 'radius': 12, 'dhcp': 13}\n",
      "2100003\n",
      "[0.2711794028719652, 0.021210040436408027, 0.6524071462129994, 9.83321850267745e-08, 0.0, 0.0, 1.2006868117486436e-07, 9.194906523326434e-06, 1.1188787524993125e-05, 0.12156862745098039, 0.11417322834645668, 0.0, 0.0, 0.0, 8.357947830722337e-05, 0.0048290753567918655, 0.00018786398647379298, 0.0001815211472136504, 0.0, 0.0, 0.0, 0.0, 0.043882978723404256, 0.05466666666666666, 0.0, 0.0, 0.0, 0.0, 1.593020328982675e-05, 0.0, 2.8328649663255683e-07, 2.185413140586619e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030303030303030304, 0.09090909090909091, 0.0, 0.030303030303030304, 0.0, 0.0, 0.0]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "[x, y] = parse(data)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "newx = min_max_scaler.fit_transform(x)\n",
    "newx = numpy.delete(numpy.asarray(newx),47,1)\n",
    "newy = y\n",
    "print(len(newx))\n",
    "newx = newx.tolist()\n",
    "print(newx[0])\n",
    "print(newy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "while(len(newx)%100000 != 0):\n",
    "    newx.pop()\n",
    "    newy.pop()\n",
    "print(len(newx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2711794028719652, 0.021210040436408027, 0.6524071462129994, 9.83321850267745e-08, 0.0, 0.0, 1.2006868117486436e-07, 9.194906523326434e-06, 1.1188787524993125e-05, 0.12156862745098039, 0.11417322834645668, 0.0, 0.0, 0.0, 8.357947830722337e-05, 0.0048290753567918655, 0.00018786398647379298, 0.0001815211472136504, 0.0, 0.0, 0.0, 0.0, 0.043882978723404256, 0.05466666666666666, 0.0, 0.0, 0.0, 0.0, 1.593020328982675e-05, 0.0, 2.8328649663255683e-07, 2.185413140586619e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030303030303030304, 0.09090909090909091, 0.0, 0.030303030303030304, 0.0, 0.0, 0.0]\n",
      "47\n",
      "2100000\n"
     ]
    }
   ],
   "source": [
    "print (newx[0])\n",
    "print (len(newx[0]))\n",
    "print (len(newx))\n",
    "\n",
    "def construct_data_for_package_memory_len(package_len, x, y):\n",
    "    x_result = []\n",
    "    y_result = []\n",
    "    for j in range (len(x) // package_len - 1):\n",
    "        for i in range (package_len):\n",
    "            temp_arr = []\n",
    "            for k in range (package_len):\n",
    "                temp_arr.append(x[j * package_len + i + k])\n",
    "            x_result.append(temp_arr)\n",
    "            y_result.append(y[j * package_len + i + package_len - 1])\n",
    "    while len(x_result) % 10000 != 0:\n",
    "        x_result.pop()\n",
    "        y_result.pop()\n",
    "    for i in range(len(x_result)):\n",
    "        for j in range(len(x_result[i])):\n",
    "            for k in range(len(x_result[i][j])):\n",
    "                if numpy.isnan(x_result[i][j][k]):\n",
    "                    x_result[i][j][k] = 1\n",
    "    return [x_result, y_result]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def CrossValidation(lenOfBlock , x, y, neurons, layers, inputshape, epochsIn, batchsize):\n",
    "    cv = KFold(n_splits = lenOfBlock, random_state = None, shuffle = True)\n",
    "        \n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TP = 0\n",
    "    F1 = 0\n",
    "    Educate = 0.0\n",
    "    Test = 0.0\n",
    "    print(\"Neurons: \", neurons)\n",
    "    print(\"Layers: \", layers)\n",
    "    numblock=0\n",
    "    x = numpy.reshape(x,(5,len(x)//5,inputshape[0],47))\n",
    "    y = numpy.reshape(y,(5,len(y)//5))\n",
    "    \n",
    "    \n",
    "    for train_index, test_index in cv.split(x[0]):\n",
    "        clf = getModel(neurons, layers, inputshape, batchsize)\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        print(\"Block: \", numblock)\n",
    "        numblock +=1\n",
    "        start_time = time.time()\n",
    "        skmetrics = SkMetrics(batchsize)\n",
    "        for i in range (epochsIn):\n",
    "            for d in range (5):\n",
    "                history = clf.fit(x[d][train_index], y[d][train_index], callbacks = [skmetrics], epochs = 1, validation_data = (x[d][test_index], y[d][test_index]), batch_size = batchsize)        \n",
    "        for k in skmetrics.confusion:\n",
    "            print(k)\n",
    "        education_time = time.time() - start_time\n",
    "        try:\n",
    "            # Тестирование\n",
    "            start_time = time.time()\n",
    "            proba = []\n",
    "            for i in range(5):\n",
    "                proba.append(numpy.round(numpy.asarray(clf.predict(x[i][test_index], batch_size = batchsize))))\n",
    "                \n",
    "            test_time = time.time() - start_time\n",
    "            # Добавляем значения\n",
    "            Educate += education_time\n",
    "            Test += test_time\n",
    "            y1 = []\n",
    "            for i in range(5):\n",
    "                y1.append(y[i][test_index].flatten())\n",
    "                cn1 = confusion_matrix(y1[i], proba[i], labels=[0,1])\n",
    "                tn1, fp1, fn1, tp1 = cn1.ravel()\n",
    "                TN += tn1 \n",
    "                FP += fp1 \n",
    "                FN += fn1\n",
    "                TP += tp1 \n",
    "                F1 += (f1_score(y1[i], proba[i] , average='binary'))\n",
    "                print(cn1)\n",
    "        except ZeroDivisionError:\n",
    "            print(\"ZeroDivisionError\")\n",
    "       \n",
    "        \n",
    "    summ = TN + FP + FN + TP\n",
    "    \n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(\"Block len \" + str(lenOfBlock))\n",
    "    print(\"True positive \" + str(TP / summ), TP)\n",
    "    print(\"True negative \" + str(TN / summ), TN)\n",
    "    print(\"False positive \" + str(FP / summ), FP)\n",
    "    print(\"False negative \" + str(FN / summ), FN)\n",
    "   \n",
    "    print(\"Accuracy \" + str((TP + TN)/(summ)))\n",
    "    print(\"Precision \" + str(TP / (TP + FP))) # Precision\n",
    "    print(\"Recall \" + str(TP / (TP + FN))) # Recall\n",
    "\n",
    "    print(\"F1 score \" + str(F1 / lenOfBlock)) # F1 score\n",
    "    print(\"Educate time \" + str(Educate / lenOfBlock)) # Educate time\n",
    "    print(\"Test time \" + str(Test / lenOfBlock)) # Test time\n",
    "\n",
    "    print(\"\\n\\n\\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#[x, y] = construct_data_for_package_memory_len(5, newx, newy)\n",
    "#x1 = numpy.array(x)\n",
    "#y1 = numpy.array(y)\n",
    "#CrossValidation(5 , x1, y1, 100, 1, (5,47), 2, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neurons:  100\n",
      "Layers:  1\n",
      "TRAIN: [     3      5      6 ... 417996 417997 417998] TEST: [     0      1      2 ... 417988 417992 417999]\n",
      "Block:  0\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 496s 1ms/step - loss: 0.0272 - acc: 0.9903 - val_loss: 0.0112 - val_acc: 0.9956\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 487s 1ms/step - loss: 5.7463e-06 - acc: 1.0000 - val_loss: 9.6498e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanet/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/vanet/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/vanet/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/vanet/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/vanet/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:576: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 483s 1ms/step - loss: 0.0140 - acc: 0.9944 - val_loss: 0.0092 - val_acc: 0.9963\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 471s 1ms/step - loss: 0.0218 - acc: 0.9909 - val_loss: 0.0180 - val_acc: 0.9925\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 412s 1ms/step - loss: 0.0185 - acc: 0.9921 - val_loss: 0.0182 - val_acc: 0.9921\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 405s 1ms/step - loss: 0.0088 - acc: 0.9965 - val_loss: 0.0083 - val_acc: 0.9967\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 402s 1ms/step - loss: 1.1348e-05 - acc: 1.0000 - val_loss: 1.5881e-06 - val_acc: 1.0000\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 445s 1ms/step - loss: 0.0081 - acc: 0.9967 - val_loss: 0.0076 - val_acc: 0.9967\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 485s 1ms/step - loss: 0.0182 - acc: 0.9923 - val_loss: 0.0167 - val_acc: 0.9929\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 488s 1ms/step - loss: 0.0163 - acc: 0.9931 - val_loss: 0.0163 - val_acc: 0.9931\n",
      "[[64862   419]\n",
      " [  159 18160]]\n",
      "[[78794   361]\n",
      " [   34  4411]]\n",
      "[[83593     7]\n",
      " [    0     0]]\n",
      "[[77327   200]\n",
      " [   61  6012]]\n",
      "[[65795   368]\n",
      " [  212 17225]]\n",
      "[[64862   419]\n",
      " [  159 18160]]\n",
      "TRAIN: [     0      1      2 ... 417997 417998 417999] TEST: [    10     15     35 ... 417985 417986 417990]\n",
      "Block:  1\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 490s 1ms/step - loss: 0.0268 - acc: 0.9909 - val_loss: 0.0118 - val_acc: 0.9951\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 487s 1ms/step - loss: 1.3818e-05 - acc: 1.0000 - val_loss: 9.3324e-07 - val_acc: 1.0000\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 486s 1ms/step - loss: 0.0135 - acc: 0.9947 - val_loss: 0.0084 - val_acc: 0.9966\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 485s 1ms/step - loss: 0.0211 - acc: 0.9910 - val_loss: 0.0202 - val_acc: 0.9916\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 486s 1ms/step - loss: 0.0184 - acc: 0.9923 - val_loss: 0.0187 - val_acc: 0.9921\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 489s 1ms/step - loss: 0.0086 - acc: 0.9967 - val_loss: 0.0087 - val_acc: 0.9967\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 509s 2ms/step - loss: 4.9341e-06 - acc: 1.0000 - val_loss: 1.8662e-06 - val_acc: 1.0000\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 489s 1ms/step - loss: 0.0082 - acc: 0.9967 - val_loss: 0.0068 - val_acc: 0.9972\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 484s 1ms/step - loss: 0.0179 - acc: 0.9925 - val_loss: 0.0178 - val_acc: 0.9927\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 487s 1ms/step - loss: 0.0164 - acc: 0.9930 - val_loss: 0.0164 - val_acc: 0.9927\n",
      "[[64735   391]\n",
      " [  220 18254]]\n",
      "[[78841   399]\n",
      " [   30  4330]]\n",
      "[[83600     0]\n",
      " [    0     0]]\n",
      "[[77437   154]\n",
      " [   75  5934]]\n",
      "[[65963   385]\n",
      " [  230 17022]]\n",
      "[[64735   391]\n",
      " [  220 18254]]\n",
      "TRAIN: [     0      1      2 ... 417996 417997 417999] TEST: [    11     19     25 ... 417982 417989 417998]\n",
      "Block:  2\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 487s 1ms/step - loss: 0.0270 - acc: 0.9904 - val_loss: 0.0166 - val_acc: 0.9930\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 484s 1ms/step - loss: 1.3034e-05 - acc: 1.0000 - val_loss: 6.8730e-07 - val_acc: 1.0000\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 485s 1ms/step - loss: 0.0129 - acc: 0.9949 - val_loss: 0.0103 - val_acc: 0.9959\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 491s 1ms/step - loss: 0.0217 - acc: 0.9908 - val_loss: 0.0196 - val_acc: 0.9916\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 485s 1ms/step - loss: 0.0182 - acc: 0.9922 - val_loss: 0.0175 - val_acc: 0.9928\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 488s 1ms/step - loss: 0.0086 - acc: 0.9966 - val_loss: 0.0082 - val_acc: 0.9969\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 486s 1ms/step - loss: 5.6924e-06 - acc: 1.0000 - val_loss: 1.9703e-06 - val_acc: 1.0000\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 488s 1ms/step - loss: 0.0078 - acc: 0.9969 - val_loss: 0.0072 - val_acc: 0.9972\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 487s 1ms/step - loss: 0.0181 - acc: 0.9924 - val_loss: 0.0168 - val_acc: 0.9931\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 486s 1ms/step - loss: 0.0162 - acc: 0.9932 - val_loss: 0.0158 - val_acc: 0.9935\n",
      "[[64693   324]\n",
      " [  223 18360]]\n",
      "[[78976   136]\n",
      " [  183  4305]]\n",
      "[[83600     0]\n",
      " [    0     0]]\n",
      "[[77342   175]\n",
      " [   89  5994]]\n",
      "[[65827   337]\n",
      " [  244 17192]]\n",
      "[[64693   324]\n",
      " [  223 18360]]\n",
      "TRAIN: [     0      1      2 ... 417997 417998 417999] TEST: [     5     12     14 ... 417981 417983 417995]\n",
      "Block:  3\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 486s 1ms/step - loss: 0.0268 - acc: 0.9908 - val_loss: 0.0131 - val_acc: 0.9951\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 485s 1ms/step - loss: 1.0852e-05 - acc: 1.0000 - val_loss: 9.6058e-07 - val_acc: 1.0000\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 486s 1ms/step - loss: 0.0122 - acc: 0.9950 - val_loss: 0.0104 - val_acc: 0.9958\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 484s 1ms/step - loss: 0.0211 - acc: 0.9912 - val_loss: 0.0205 - val_acc: 0.9913\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 482s 1ms/step - loss: 0.0187 - acc: 0.9920 - val_loss: 0.0164 - val_acc: 0.9931\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 486s 1ms/step - loss: 0.0085 - acc: 0.9967 - val_loss: 0.0097 - val_acc: 0.9963\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 417s 1ms/step - loss: 5.1947e-06 - acc: 1.0000 - val_loss: 2.3647e-06 - val_acc: 1.0000\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 406s 1ms/step - loss: 0.0078 - acc: 0.9968 - val_loss: 0.0083 - val_acc: 0.9966\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 406s 1ms/step - loss: 0.0178 - acc: 0.9925 - val_loss: 0.0181 - val_acc: 0.9925\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 515s 2ms/step - loss: 0.0165 - acc: 0.9931 - val_loss: 0.0146 - val_acc: 0.9938\n",
      "[[64697   355]\n",
      " [  161 18387]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[78999   199]\n",
      " [  129  4273]]\n",
      "[[83599     1]\n",
      " [    0     0]]\n",
      "[[77467   183]\n",
      " [   80  5870]]\n",
      "[[65786   370]\n",
      " [  223 17221]]\n",
      "[[64697   355]\n",
      " [  161 18387]]\n",
      "TRAIN: [     0      1      2 ... 417995 417998 417999] TEST: [     3      6      7 ... 417994 417996 417997]\n",
      "Block:  4\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 456s 1ms/step - loss: 0.0278 - acc: 0.9905 - val_loss: 0.0109 - val_acc: 0.9957\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 410s 1ms/step - loss: 9.2887e-06 - acc: 1.0000 - val_loss: 1.6423e-06 - val_acc: 1.0000\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 412s 1ms/step - loss: 0.0130 - acc: 0.9948 - val_loss: 0.0098 - val_acc: 0.9960\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 411s 1ms/step - loss: 0.0214 - acc: 0.9909 - val_loss: 0.0252 - val_acc: 0.9894\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 413s 1ms/step - loss: 0.0183 - acc: 0.9922 - val_loss: 0.0173 - val_acc: 0.9928\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 409s 1ms/step - loss: 0.0090 - acc: 0.9965 - val_loss: 0.0075 - val_acc: 0.9969\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 406s 1ms/step - loss: 7.2114e-06 - acc: 1.0000 - val_loss: 1.8613e-06 - val_acc: 1.0000\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 411s 1ms/step - loss: 0.0081 - acc: 0.9967 - val_loss: 0.0086 - val_acc: 0.9966\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 480s 1ms/step - loss: 0.0178 - acc: 0.9925 - val_loss: 0.0169 - val_acc: 0.9928\n",
      "Train on 334400 samples, validate on 83600 samples\n",
      "Epoch 1/1\n",
      "334400/334400 [==============================] - 467s 1ms/step - loss: 0.0162 - acc: 0.9932 - val_loss: 0.0166 - val_acc: 0.9935\n",
      "[[64936   279]\n",
      " [  264 18121]]\n",
      "[[78972   111]\n",
      " [  212  4305]]\n",
      "[[83600     0]\n",
      " [    0     0]]\n",
      "[[77460   148]\n",
      " [  130  5862]]\n",
      "[[65928   329]\n",
      " [  289 17054]]\n",
      "[[64936   279]\n",
      " [  264 18121]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Block len 5\n",
      "True positive 0.10923062200956937 228292\n",
      "True negative 0.886521052631579 1852829\n",
      "False positive 0.0026942583732057416 5631\n",
      "False negative 0.001554066985645933 3248\n",
      "Accuracy 0.9957516746411483\n",
      "Precision 0.9759279762998936\n",
      "Recall 0.9859721862313208\n",
      "F1 score 3.906651651766901\n",
      "Educate time 5545.3914324760435\n",
      "Test time 202.11770176887512\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "[x, y] = construct_data_for_package_memory_len(40, newx, newy)\n",
    "x1 = numpy.array(x)\n",
    "y1 = numpy.array(y)\n",
    "CrossValidation(5 , x1, y1, 100, 1, (40,47), 2, 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x, y] = construct_data_for_package_memory_len(20, newx, newy)\n",
    "x1 = numpy.array(x)\n",
    "y1 = numpy.array(y)\n",
    "CrossValidation(5 , x1, y1, 100, 1, (20,47), 2, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x, y] = construct_data_for_package_memory_len(2, newx, newy)\n",
    "x1 = numpy.array(x)\n",
    "y1 = numpy.array(y)\n",
    "CrossValidation(5 , x1, y1, 100, 1, (2,47), 2, 200)\n",
    "\n",
    "[x, y] = construct_data_for_package_memory_len(4, newx, newy)\n",
    "x1 = numpy.array(x)\n",
    "y1 = numpy.array(y)\n",
    "CrossValidation(5 , x1, y1, 100, 1, (4,47), 2, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x, y] = construct_data_for_package_memory_len(7, newx, newy)\n",
    "x1 = numpy.array(x)\n",
    "y1 = numpy.array(y)\n",
    "CrossValidation(5 , x1, y1, 100, 1, (7,47), 2, 200)\n",
    "\n",
    "[x, y] = construct_data_for_package_memory_len(3, newx, newy)\n",
    "x1 = numpy.array(x)\n",
    "y1 = numpy.array(y)\n",
    "CrossValidation(5 , x1, y1, 100, 1, (3,47), 2, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
